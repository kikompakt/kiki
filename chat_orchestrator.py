"""
Chat-Orchestrator f√ºr Intelligentes KI-Kursstudio
Dynamisches Assistant-Management aus Datenbank

NEUE FEATURES:
- Dynamische Assistant-Verwaltung aus DB
- Flexible Tool-Call-Routing
- User-konfigurierbare Workflows
- MEMORY MANAGEMENT: TTL-basiertes Cleanup-System mit Singleton-Pattern
- TYPE SAFETY: Umfassende Type-Hints f√ºr bessere Code-Qualit√§t
"""

import os
import json
import time
import sqlite3
import threading
import gc
import logging
import base64
import re
from datetime import datetime, timedelta
from typing import Dict, Optional, Any, List

from openai import OpenAI
from dotenv import load_dotenv
from quality_assessment import assess_course_quality

# .env-Datei laden
load_dotenv()

# OpenAI Client initialisieren (Singleton Pattern)
_openai_client = None

def get_openai_client() -> OpenAI:
    """Singleton Pattern f√ºr OpenAI Client - verhindert Memory-Leak durch zu viele Instanzen"""
    global _openai_client
    if _openai_client is None:
        _openai_client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    return _openai_client

# Global orchestrator instance f√ºr Web-App Integration mit Cleanup-System
active_orchestrators: Dict[str, 'DynamicChatOrchestrator'] = {}
orchestrator_last_activity: Dict[str, datetime] = {}

# Memory Management Konfiguration
ORCHESTRATOR_TTL_MINUTES = 30  # Time-to-live f√ºr inaktive Orchestrators
MAX_CONCURRENT_ORCHESTRATORS = 50  # Maximum gleichzeitige Orchestrators
CLEANUP_INTERVAL_MINUTES = 10  # Cleanup-Interval

logger = logging.getLogger(__name__)

def cleanup_inactive_orchestrators():
    """
    MEMORY MANAGEMENT: Bereinigt inaktive Orchestrators zur Memory-Optimierung
    Wird automatisch vom Scheduler aufgerufen
    """
    global active_orchestrators, orchestrator_last_activity
    
    now = datetime.now()
    ttl_threshold = now - timedelta(minutes=ORCHESTRATOR_TTL_MINUTES)
    cleanup_count = 0
    
    # Identifiziere inaktive Orchestrators
    inactive_keys = []
    for key, last_activity in orchestrator_last_activity.items():
        if last_activity < ttl_threshold:
            inactive_keys.append(key)
    
    # Bereinige inaktive Orchestrators
    for key in inactive_keys:
        if key in active_orchestrators:
            try:
                # Orchestrator cleanup
                orchestrator = active_orchestrators[key]
                orchestrator._cleanup()
                del active_orchestrators[key]
                del orchestrator_last_activity[key]
                cleanup_count += 1
            except Exception as e:
                logger.warning(f"Orchestrator cleanup error f√ºr {key}: {e}")
    
    # Force Garbage Collection bei gr√∂√üeren Cleanups
    if cleanup_count > 5:
        gc.collect()
    
    logger.info(f"üßπ Memory Cleanup: {cleanup_count} inaktive Orchestrators bereinigt. Aktiv: {len(active_orchestrators)}")
    
    # Limit enforcement: Bei zu vielen aktiven Orchestrators √§lteste entfernen
    if len(active_orchestrators) > MAX_CONCURRENT_ORCHESTRATORS:
        sorted_by_activity = sorted(orchestrator_last_activity.items(), key=lambda x: x[1])
        excess_count = len(active_orchestrators) - MAX_CONCURRENT_ORCHESTRATORS
        
        for key, _ in sorted_by_activity[:excess_count]:
            if key in active_orchestrators:
                try:
                    active_orchestrators[key]._cleanup()
                    del active_orchestrators[key]
                    del orchestrator_last_activity[key]
                except Exception as e:
                    logger.warning(f"Force cleanup error f√ºr {key}: {e}")
        
        gc.collect()
        logger.info(f"üö® Force cleanup: {excess_count} Orchestrators entfernt. Limit: {MAX_CONCURRENT_ORCHESTRATORS}")

def get_or_create_orchestrator(project_id: str, session_id: str, socketio) -> 'DynamicChatOrchestrator':
    """
    MEMORY MANAGEMENT: Factory-Function f√ºr Orchestrators mit Activity-Tracking
    """
    orchestrator_key = f"{project_id}_{session_id}"
    
    # Update activity timestamp
    orchestrator_last_activity[orchestrator_key] = datetime.now()
    
    # Return existing orchestrator
    if orchestrator_key in active_orchestrators:
        return active_orchestrators[orchestrator_key]
    
    # Create new orchestrator
    orchestrator = DynamicChatOrchestrator(
        socketio=socketio,
        project_id=project_id,
        session_id=session_id
    )
    
    active_orchestrators[orchestrator_key] = orchestrator
    logger.info(f"ü§ñ Neuer Orchestrator erstellt: {orchestrator_key}. Aktiv: {len(active_orchestrators)}")
    
    # Trigger cleanup if nearing limit
    if len(active_orchestrators) > MAX_CONCURRENT_ORCHESTRATORS * 0.8:
        threading.Thread(target=cleanup_inactive_orchestrators, daemon=True).start()
    
    return orchestrator

class DynamicChatOrchestrator:
    """
    NEUE DYNAMISCHE VERSION: Chat-Orchestrator mit DB-basiertem Assistant-Management
    
    Features:
    - SocketIO Integration f√ºr Live-Updates
    - Dynamische Assistant-Verwaltung aus Datenbank
    - Flexible Tool-Call-Routing
    - User-konfigurierbare Workflows
    - MEMORY MANAGEMENT: TTL-basiertes Cleanup-System
    """
    
    def __init__(self, socketio, project_id: Optional[str] = None, session_id: Optional[str] = None):
        self.socketio = socketio
        self.project_id = project_id
        self.session_id = session_id
        self.client = get_openai_client()  # Singleton Client verwenden
        self.supervisor_assistant = None
        self.assistants: Dict[str, Dict[str, Any]] = {}  # Cache f√ºr alle verf√ºgbaren Assistants
        self.thread = None
        self.current_run = None
        self.is_processing = False
        
        # Memory tracking
        self.created_at = datetime.now()
        self.last_activity = datetime.now()
        
        # Chat-spezifische Einstellungen
        self.chat_mode = "collaborative"  # collaborative oder autonomous
        self.response_callbacks = []
        
        # Final content tracking
        self.course_content_stages: Dict[str, str] = {}  # Track content through each stage
        self.final_course_content = ""  # The complete final course
        
        # Assistants beim Start laden
        self._load_assistants_from_db()
        
        # Activity tracking aktualisieren
        self._update_activity()
    
    def _update_activity(self):
        """Aktualisiert Activity-Timestamp f√ºr Memory-Management"""
        self.last_activity = datetime.now()
        orchestrator_key = f"{self.project_id}_{self.session_id}"
        orchestrator_last_activity[orchestrator_key] = self.last_activity
    
    def _cleanup(self):
        """
        MEMORY MANAGEMENT: Bereinigt Orchestrator-Ressourcen
        """
        try:
            # OpenAI Thread cleanup
            if self.current_run:
                try:
                    self.client.beta.threads.runs.cancel(
                        thread_id=self.thread.id, 
                        run_id=self.current_run.id
                    )
                except:
                    pass  # Silent fail f√ºr cleanup
            
            # Clear references
            self.thread = None
            self.current_run = None
            self.assistants.clear()
            self.course_content_stages.clear()
            self.response_callbacks.clear()
            
            # SocketIO cleanup
            if self.socketio and self.session_id:
                try:
                    self.socketio.emit('orchestrator_cleanup', {
                        'message': 'Session bereinigt f√ºr Memory-Optimierung'
                    }, room=f'session_{self.session_id}')
                except:
                    pass
            
            logger.info(f"üßπ Orchestrator cleanup abgeschlossen f√ºr {self.project_id}_{self.session_id}")
            
        except Exception as e:
            logger.warning(f"Cleanup error: {e}")
    
    def _load_assistants_from_db(self):
        """L√§dt alle aktiven Assistants aus der SQLAlchemy-Datenbank (PostgreSQL/SQLite)."""
        try:
            # Lazy import to avoid circular dependency
            from models import db, Assistant  # noqa: E402
            from flask import current_app
            
            # CRITICAL FIX: Ensure we're in Flask app context
            with current_app.app_context():
                assistants = Assistant.query.filter_by(is_active=True).order_by(Assistant.order_index.asc()).all()
                
                # Cache assistants
                for assistant in assistants:
                    assistant_data = {
                        'id': assistant.id,
                        'name': assistant.name,
                        'assistant_id': assistant.assistant_id,
                        'role': assistant.role,
                        'description': assistant.description,
                        'instructions': assistant.instructions,
                        'model': assistant.model,
                        'temperature': assistant.temperature,
                        'top_p': assistant.top_p,
                        'max_tokens': assistant.max_tokens,
                        'frequency_penalty': assistant.frequency_penalty,
                        'presence_penalty': assistant.presence_penalty,
                        'retry_attempts': assistant.retry_attempts,
                        'timeout_seconds': assistant.timeout_seconds,
                        'enabled_tools': json.loads(assistant.enabled_tools) if assistant.enabled_tools else []
                    }
                    self.assistants[assistant.role] = assistant_data
                    
                    # Mark supervisor assistant
                    if assistant.role == 'supervisor':
                        self.supervisor_assistant_id = assistant.assistant_id
                        self.emit_status(f"‚úÖ Supervisor Assistant geladen: {self.supervisor_assistant_id}")
                
                if not self.assistants:
                    self.emit_status("‚ö†Ô∏è Keine aktiven Assistants in der Datenbank gefunden")
                    
        except Exception as e:
            logger.error(f"Assistant-Load-Error: {e}")
            self.emit_error(f"Assistant-Load-Error: {e}")
            # FALLBACK: Create a basic supervisor assistant if DB fails
            self._create_fallback_supervisor()
    
    def _create_fallback_supervisor(self):
        """Creates fallback assistants when database is not available"""
        logger.info("üîÑ Creating fallback assistants (no database access)")
        
        # Create comprehensive fallback assistant data
        fallback_assistants = {
            'supervisor': {
                'id': 1,
                'name': 'Fallback Supervisor',
                'assistant_id': 'asst_19FlW2QtTAIb7Z96f3ukfSre',
                'role': 'supervisor',
                'description': 'Fallback Supervisor f√ºr lokale Entwicklung',
                'instructions': self._get_supervisor_instructions(),
                'model': 'gpt-4o',
                'temperature': 0.7,
                'top_p': 1.0,
                'max_tokens': 2000,
                'frequency_penalty': 0.0,
                'presence_penalty': 0.0,
                'retry_attempts': 3,
                'timeout_seconds': 300,
                'enabled_tools': ['create_content','optimize_didactics','critically_review','request_user_feedback','knowledge_lookup']
            },
            'content_creator': {
                'id': 2,
                'name': 'Fallback Content Creator',
                'assistant_id': 'asst_19FlW2QtTAIb7Z96f3ukfSre',  # Use same assistant ID
                'role': 'content_creator',
                'description': 'Fallback Content Creator f√ºr Kursinhalte',
                'instructions': '''Du bist ein Experte f√ºr die Erstellung von hochwertigen Lerninhalten.
                
DEINE AUFGABE: Erstelle strukturierte, professionelle Kursinhalte basierend auf dem gegebenen Thema.
Erstelle immer vollst√§ndige, sofort einsetzbare Kursinhalte mit klaren Lernzielen, logischem Aufbau und praktischen Beispielen.''',
                'model': 'gpt-4o',
                'temperature': 0.3,
                'max_tokens': 3000
            },
            'didactic_expert': {
                'id': 3,
                'name': 'Fallback Didactic Expert',
                'assistant_id': 'asst_19FlW2QtTAIb7Z96f3ukfSre',
                'role': 'didactic_expert',
                'description': 'Fallback Didactic Expert f√ºr didaktische Optimierung',
                'instructions': '''Du bist ein Didaktik-Experte f√ºr die Optimierung von Lerninhalten.
                
DEINE AUFGABE: Optimiere vorhandene Kursinhalte didaktisch und methodisch.
Gib den vollst√§ndig optimierten Kursinhalt aus (nicht nur Verbesserungsvorschl√§ge)!''',
                'model': 'gpt-4o',
                'temperature': 0.4,
                'max_tokens': 3000
            },
            'quality_checker': {
                'id': 4,
                'name': 'Fallback Quality Checker',
                'assistant_id': 'asst_19FlW2QtTAIb7Z96f3ukfSre',
                'role': 'quality_checker',
                'description': 'Fallback Quality Checker f√ºr finale Pr√ºfung',
                'instructions': '''Du bist ein Qualit√§ts-Experte f√ºr die finale Pr√ºfung von Kursinhalten.
                
DEINE AUFGABE: F√ºhre eine kritische Qualit√§tspr√ºfung durch und korrigiere M√§ngel.
Gib den vollst√§ndig korrigierten und qualit√§tsgesicherten Kurs aus!''',
                'model': 'gpt-4o',
                'temperature': 0.2,
                'max_tokens': 3000
            }
        }
        
        # Load all fallback assistants
        for role, assistant_data in fallback_assistants.items():
            self.assistants[role] = assistant_data
            logger.info(f"‚úÖ Fallback {role} assistant created")
        
        self.supervisor_assistant_id = fallback_assistants['supervisor']['assistant_id']
        
        logger.info(f"‚úÖ All fallback assistants created: {list(fallback_assistants.keys())}")
        self.emit_status(f"‚úÖ Fallback Assistants geladen: {len(fallback_assistants)} Rollen verf√ºgbar")

    def get_or_create_assistant(self):
        """
        NEUE DYNAMISCHE VERSION: Verwendet Supervisor aus Datenbank mit Tool-Setup
        """
        if not hasattr(self, 'supervisor_assistant_id'):
            self.emit_error("‚ùå Kein Supervisor-Assistant in der Datenbank konfiguriert")
            return False
            
        try:
            # Supervisor Assistant aus Datenbank laden
            self.supervisor_assistant = self.client.beta.assistants.retrieve(self.supervisor_assistant_id)
            
            # CRITICAL FIX: Stelle sicher, dass Tools konfiguriert sind
            required_tools = self._get_required_tools()
            current_tools = self.supervisor_assistant.tools or []
            
            # Pr√ºfe ob Tools fehlen oder veraltet sind ODER Instructions aktualisiert werden m√ºssen
            needs_update = not self._tools_are_current(current_tools, required_tools)
            current_instructions = getattr(self.supervisor_assistant, 'instructions', '')
            new_instructions = self._get_supervisor_instructions()
            
            # Force update if instructions changed or tools outdated
            if needs_update or current_instructions != new_instructions:
                self.emit_status("üîß Aktualisiere Supervisor (Tools & Instructions)...")
                
                # Update Assistant mit korrekten Tools und Instructions
                self.supervisor_assistant = self.client.beta.assistants.update(
                    assistant_id=self.supervisor_assistant_id,
                    tools=required_tools,
                    instructions=new_instructions
                )
                
                self.emit_status("‚úÖ Supervisor vollst√§ndig aktualisiert")
            
            self.emit_status(f"‚úÖ Supervisor Assistant geladen: {self.supervisor_assistant_id}")
            return True
            
        except Exception as e:
            self.emit_error(f"‚ùå Fehler beim Laden des Supervisor Assistants: {e}")
            return False
    
    def get_api_parameters_for_assistant(self, role):
        """Extrahiert OpenAI API-Parameter f√ºr spezifischen Assistant-Role."""
        assistant = self.assistants.get(role, {})
        
        # Standard-Parameter falls Assistant nicht gefunden
        defaults = {
            'temperature': 0.7,
            'top_p': 1.0, 
            'max_tokens': 2000,
            'frequency_penalty': 0.0,
            'presence_penalty': 0.0
        }
        
        # Erweiterte Parameter aus DB laden
        api_params = {
            'temperature': assistant.get('temperature', defaults['temperature']),
            'top_p': assistant.get('top_p', defaults['top_p']),
            'max_tokens': assistant.get('max_tokens', defaults['max_tokens']),
            'frequency_penalty': assistant.get('frequency_penalty', defaults['frequency_penalty']),
            'presence_penalty': assistant.get('presence_penalty', defaults['presence_penalty'])
        }
        
        # Workflow-Parameter auch verf√ºgbar machen
        workflow_params = {
            'retry_attempts': assistant.get('retry_attempts', 3),
            'timeout_seconds': assistant.get('timeout_seconds', 180),
            'error_handling': assistant.get('error_handling', 'graceful'),
            'response_limit': assistant.get('response_limit', 30),
            'context_window': assistant.get('context_window', 128000)
        }
        
        return api_params, workflow_params
    
    def _get_required_tools(self):
        """Definiert die erforderlichen Tool-Calls f√ºr Multi-Agenten-System"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "create_content",
                    "description": "Erstellt einen ersten Rohentwurf f√ºr ein gegebenes Thema mit Content Creator Agent.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "topic": {
                                "type": "string",
                                "description": "Das Thema, zu dem der Inhalt erstellt werden soll."
                            },
                            "instructions": {
                                "type": "string", 
                                "description": "Spezifische Anweisungen f√ºr die Inhaltserstellung."
                            },
                            "content_type": {
                                "type": "string",
                                "description": "Der Typ des zu erstellenden Inhalts: 'outline' f√ºr Inhaltsverzeichnis oder 'full_content' f√ºr vollst√§ndigen Inhalt.",
                                "enum": ["outline", "full_content"]
                            }
                        },
                        "required": ["topic", "instructions", "content_type"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "optimize_didactics",
                    "description": "Optimiert vorhandenen Inhalt didaktisch mit Didactic Expert Agent.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "content": {
                                "type": "string",
                                "description": "Der zu optimierende Inhalt."
                            }
                        },
                        "required": ["content"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "critically_review",
                    "description": "Pr√ºft Inhalt kritisch auf Logik, Fakten und Konsistenz mit Quality Checker Agent.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "content": {
                                "type": "string",
                                "description": "Der zu pr√ºfende Inhalt."
                            },
                            "review_type": {
                                "type": "string",
                                "description": "Der Typ der Pr√ºfung: 'outline' f√ºr Inhaltsverzeichnis-Review oder 'full_content' f√ºr vollst√§ndige Inhaltspr√ºfung.",
                                "enum": ["outline", "full_content"]
                            }
                        },
                        "required": ["content", "review_type"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "request_outline_approval",
                    "description": "Zeigt dem User das gepr√ºfte Inhaltsverzeichnis und fragt nach Freigabe f√ºr die Volltext-Erstellung. User kann √Ñnderungen vorschlagen.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "outline": {
                                "type": "string",
                                "description": "Das detaillierte Inhaltsverzeichnis mit Kapiteln, Lernzielen und groben Beschreibungen."
                            },
                            "quality_feedback": {
                                "type": "string",
                                "description": "Das Feedback vom Quality Checker zum Outline."
                            },
                            "topic": {
                                "type": "string",
                                "description": "Das Kursthema."
                            }
                        },
                        "required": ["outline", "quality_feedback", "topic"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "request_user_feedback", 
                    "description": "Fordert finales Feedback vom User f√ºr den vollst√§ndig erstellten Kursinhalt.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "content": {
                                "type": "string",
                                "description": "Der finale Kursinhalt f√ºr den Feedback ben√∂tigt wird."
                            },
                            "question": {
                                "type": "string",
                                "description": "Die spezifische Frage an den User."
                            },
                            "stage": {
                                "type": "string",
                                "description": "Das Stadium des Workflows (z.B. 'final_approval')."
                            }
                        },
                        "required": ["content", "question", "stage"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "knowledge_lookup",
                    "description": "Durchsucht die projektspezifische Wissensbasis nach relevanten Informationen.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "Die Suchanfrage f√ºr die Wissensbasis."
                            },
                            "context": {
                                "type": "string",
                                "description": "Zus√§tzlicher Kontext f√ºr die Suche."
                            }
                        },
                        "required": ["query"]
                    }
                }
            }
        ]
    
    def _tools_are_current(self, current_tools, required_tools):
        """Pr√ºft ob die aktuellen Tools mit den erforderlichen √ºbereinstimmen"""
        if len(current_tools) != len(required_tools):
            return False
        
        # Einfache Pr√ºfung: Schaue nach den Function-Namen
        current_names = set()
        for tool in current_tools:
            if tool.type == "function" and hasattr(tool, 'function'):
                current_names.add(tool.function.name)
        
        required_names = set()
        for tool in required_tools:
            if tool["type"] == "function":
                required_names.add(tool["function"]["name"])
        
        return current_names == required_names
    
    def _get_supervisor_instructions(self):
        """Einfache, klare Instructions f√ºr den Supervisor-Assistant"""
        return """Du bist ein intelligenter KI-Supervisor f√ºr automatische Kurserstellung.

DEINE AUFGABE: Erkenne die Nutzerintention und handle entsprechend:

üéØ BEI EXPLIZITEN KURSANFRAGEN:
Wenn der User eindeutig einen Kurs erstellen m√∂chte (erkennbar an W√∂rtern wie "Kurs", "erstelle", "Training", "Schulung", "Lerninhalt"):

F√ºhre automatisch diese 3 Schritte aus:
1. create_content(topic="[Thema]", instructions="Erstelle einen professionellen Kurs")
2. optimize_didactics(content="[Ergebnis von Schritt 1]")  
3. critically_review(content="[Ergebnis von Schritt 2]")

WICHTIG f√ºr Kurserstellung:
- F√ºhre ALLE 3 Schritte automatisch aus
- Verwende die Tool-Outputs direkt weiter
- Frage NICHT nach Best√§tigung zwischen den Schritten
- Nach Schritt 3 sagst du: "Kurs wurde erfolgreich erstellt!"

üí¨ BEI ANDEREN ANFRAGEN:
- Allgemeine Fragen: Beantworte freundlich und kompetent
- Unklare Themen: Stelle R√ºckfragen ("Zu welchem Thema soll der Kurs erstellt werden?")
- Begr√º√üungen: Antworte h√∂flich und erkl√§re deine F√§higkeiten

BEISPIELE:
‚úÖ "Erstelle einen Kurs √ºber Python" ‚Üí Starte Workflow
‚úÖ "Ich brauche ein Training zu Vertrieb" ‚Üí Starte Workflow  
‚ùå "Was kannst du?" ‚Üí Erkl√§re F√§higkeiten (KEIN Workflow)
‚ùå "Wie funktioniert das?" ‚Üí Beantworte Frage (KEIN Workflow)

Analysiere die Nutzeranfrage sorgf√§ltig und handle situationsgerecht!"""
    
    def create_thread(self):
        """Erstellt einen neuen Chat-Thread."""
        try:
            self.thread = self.client.beta.threads.create()
            self.emit_status(f"‚úÖ Chat-Thread erstellt: {self.thread.id}")
            return True
        except Exception as e:
            self.emit_error(f"‚ùå Thread-Erstellung fehlgeschlagen: {e}")
            return False
    
    def process_message(self, message: str, user_id: int = 1):
        """
        MAIN METHOD: Verarbeitet User-Nachrichten mit dynamischen DB-Assistants
        MEMORY OPTIMIZED: Activity-Tracking f√ºr TTL-Management
        """
        logger.info(f"üéØ PROCESS_MESSAGE START: user_id={user_id}, message='{message}'")
        
        self._update_activity()  # Track activity f√ºr Memory-Management
        
        if self.is_processing:
            logger.warning(f"‚è≥ Already processing for user {user_id}")
            self.emit_message("‚è≥ Ein anderer Prozess l√§uft bereits. Bitte warten Sie einen Moment.", "assistant")
            return
        
        # INTENT DETECTION: Check if this is a simple greeting or small talk
        intent = self._detect_intent(message)
        if intent in ['greeting', 'small_talk']:
            logger.info(f"ü§ù Intent detected as {intent}, sending direct response")
            self._handle_simple_response(message, intent)
            return
        
        # CRITICAL: Supervisor-Assistant sicherstellen
        logger.info(f"üîç Loading supervisor assistant for user {user_id}")
        if not self.get_or_create_assistant():
            logger.error(f"‚ùå Failed to load supervisor assistant for user {user_id}")
            self.emit_error("‚ùå Supervisor-Assistant konnte nicht geladen werden")
            return
        
        logger.info(f"‚úÖ Supervisor assistant loaded for user {user_id}")
        
        self.is_processing = True
        self.emit_status("ü§ñ KI-Agent arbeitet...")
        
        try:
            # Thread erstellen falls nicht vorhanden
            if not self.thread:
                logger.info(f"üßµ Creating new thread for user {user_id}")
                self.thread = self.client.beta.threads.create()
                self.emit_status("‚úÖ Neuer Thread erstellt")
                logger.info(f"‚úÖ Thread created: {self.thread.id}")
            else:
                logger.info(f"üîÑ Using existing thread: {self.thread.id}")
            
            # Nachricht zum Thread hinzuf√ºgen
            logger.info(f"üìù Adding message to thread for user {user_id}")
            self.client.beta.threads.messages.create(
                thread_id=self.thread.id,
                role="user",
                content=message
            )
            logger.info(f"‚úÖ Message added to thread")
            
            # Run starten
            logger.info(f"üöÄ Starting run with assistant: {self.supervisor_assistant.id}")
            self.current_run = self.client.beta.threads.runs.create(
                thread_id=self.thread.id,
                assistant_id=self.supervisor_assistant.id
            )
            logger.info(f"‚úÖ Run created: {self.current_run.id}")
            
            # Monitoring starten
            logger.info(f"üëÅÔ∏è Starting run monitoring for user {user_id}")
            self._monitor_run()
            logger.info(f"‚úÖ Run monitoring completed for user {user_id}")
            
        except Exception as e:
            logger.error(f"‚ùå Error in process_message for user {user_id}: {e}")
            logger.error(f"‚ùå Exception details: {type(e).__name__}: {str(e)}")
            self.emit_error(f"‚ùå Fehler bei der Nachrichtenverarbeitung: {e}")
        finally:
            self.is_processing = False
            self._update_activity()
            logger.info(f"üèÅ PROCESS_MESSAGE END: user_id={user_id}")
    
    def force_recovery(self):
        """Erzwingt Recovery bei h√§ngenden Runs mit sofortigem Neustart"""
        self._update_activity()
        
        try:
            if self.current_run:
                self.emit_status("üîÑ Stoppe h√§ngenden Run...")
                try:
                    self.client.beta.threads.runs.cancel(thread_id=self.thread.id, run_id=self.current_run.id)
                    self.emit_status("‚úÖ Alter Run erfolgreich gestoppt")
                except Exception as cancel_error:
                    self.emit_status(f"‚ö†Ô∏è Run-Cancel Fehler (wird ignoriert): {cancel_error}")
                
                # Status zur√ºcksetzen
                self.current_run = None
                time.sleep(1)  # Kurze Pause
                
                self.emit_status("üîÑ Starte neuen Run f√ºr Recovery...")
                
                # Neuen Run erstellen
                try:
                    self.current_run = self.client.beta.threads.runs.create(
                        thread_id=self.thread.id,
                        assistant_id=self.supervisor_assistant.id
                    )
                    
                    self.emit_status("‚úÖ Recovery-Run erstellt - Monitoring wird fortgesetzt...")
                    # Continue monitoring the new run
                    self._monitor_run()
                    
                except Exception as new_run_error:
                    self.emit_error(f"‚ùå Recovery-Run Fehler: {new_run_error}")
                    self.emit_message("Recovery fehlgeschlagen. Bitte senden Sie Ihre Nachricht erneut oder nutzen Sie 'reset' f√ºr einen kompletten Neustart.", "assistant")
                
            else:
                self.emit_status("‚ÑπÔ∏è Kein aktiver Run gefunden. System ist bereit f√ºr neue Nachrichten.")
                
        except Exception as e:
            self.emit_error(f"‚ùå Recovery-Fehler: {e}")
            self.emit_message("System-Recovery fehlgeschlagen. Bitte nutzen Sie 'reset' f√ºr einen manuellen Neustart oder senden Sie Ihre Nachricht erneut.", "assistant")
        finally:
            self.is_processing = False
            self._update_activity()
    
    def _process_message_async(self, message, user_data):
        """Asynchrone Nachrichtenverarbeitung"""
        self.is_processing = True
        
        try:
            # Initialisierung falls n√∂tig
            if not self.supervisor_assistant:
                if not self.get_or_create_assistant():
                    return
                    
            if not self.thread:
                if not self.create_thread():
                    return
            
            # User-Nachricht zum Thread hinzuf√ºgen
            self.client.beta.threads.messages.create(
                thread_id=self.thread.id,
                role="user",
                content=message
            )
            
            # Run starten
            self.current_run = self.client.beta.threads.runs.create(
                thread_id=self.thread.id,
                assistant_id=self.supervisor_assistant.id
            )
            
            # Run-Status √ºberwachen
            self._monitor_run()
            
        except Exception as e:
            self.emit_error(f"‚ùå Verarbeitungsfehler: {e}")
        finally:
            self.is_processing = False
    
    def _monitor_run(self):
        """√úberwacht den Run-Status und verarbeitet Tool-Calls mit erweiterten Workflow-Parametern"""
        
        # Workflow-Parameter f√ºr Supervisor aus DB laden
        _, workflow_params = self.get_api_parameters_for_assistant('supervisor')
        max_iterations = workflow_params.get('retry_attempts', 3) * 15  # Mehr Iterations bei h√∂heren Retry-Werten
        timeout_seconds = workflow_params.get('timeout_seconds', 180)
        error_handling = workflow_params.get('error_handling', 'graceful')
        
        iteration = 0
        stuck_count = 0  # Counter f√ºr h√§ngende Runs
        last_status = None
        queued_count = 0  # Special counter for queued status
        start_time = time.time()
        
        self.emit_status(f"üîÑ Monitoring mit Timeout: {timeout_seconds}s, Max-Iterations: {max_iterations}, Error-Handling: {error_handling}")
        
        while iteration < max_iterations:
            try:
                # Timeout-Check basierend auf DB-Parameter
                if time.time() - start_time > timeout_seconds:
                    self.emit_status(f"‚è∞ Timeout nach {timeout_seconds}s erreicht")
                    if error_handling == 'graceful':
                        self.emit_error("Entschuldigung, die Verarbeitung dauert zu lange. Bitte versuchen Sie es erneut.")
                        return
                    elif error_handling == 'retry':
                        self.emit_status("üîÑ Automatischer Restart nach Timeout...")
                        self.force_recovery()
                        return
                    else:  # strict
                        self.emit_error("‚ùå Verarbeitung wegen Timeout abgebrochen.")
                        return

                run = self.client.beta.threads.runs.retrieve(
                    thread_id=self.thread.id,
                    run_id=self.current_run.id
                )
                
                # Stuck-Detection: Wenn Status l√§nger als X Iterationen gleich bleibt
                if run.status == last_status:
                    stuck_count += 1
                else:
                    stuck_count = 0
                    last_status = run.status
                
                # Special handling for queued status - much more aggressive
                if run.status == "queued":
                    queued_count += 1
                    self.emit_status(f"‚è≥ In Warteschlange... ({queued_count}/15)")
                    
                    # AGGRESSIVE: Cancel after 15 iterations for queued (30 seconds)
                    if queued_count >= 15:
                        self.emit_status("üö® Run h√§ngt in Queue - Force Recovery...")
                        self.force_recovery()
                        return
                else:
                    queued_count = 0
                
                # General stuck detection (reduced to 6 iterations = 12s)
                if stuck_count >= 6 and run.status in ["queued", "in_progress"]:
                    self.emit_status(f"üö® Run h√§ngt bei Status '{run.status}' - Automatische Recovery...")
                    self.force_recovery()
                    return
                
                if run.status == "completed":
                    # Run erfolgreich abgeschlossen, finale Antwort abrufen
                    messages = self.client.beta.threads.messages.list(
                        thread_id=self.thread.id,
                        limit=1
                    )
                    
                    # Pr√ºfen, ob eine Nachricht vorhanden ist
                    if messages.data and messages.data[0].content:
                        response = messages.data[0].content[0].text.value
                        
                        # === HIER IST DIE WICHTIGE √ÑNDERUNG ZUR DIAGNOSE ===
                        print(f"DEBUG: Sende folgende Antwort an das Frontend: '{response}'")
                        
                        # CRITICAL NEW FEATURE: Save course content if workflow completed successfully
                        if self._is_course_creation_complete(response):
                            logger.info("üéì Course creation detected as complete, saving to database...")
                            self._save_course_to_database(response)
                        
                        self.emit_message(response, "assistant")
                    else:
                        # Dieser Fall wird eintreten, wenn die KI nichts antwortet
                        print("DEBUG: Keine Text-Antwort von OpenAI erhalten. Die Antwort war leer.")
                        
                    break
                    
                elif run.status == "requires_action":
                    # Tool-Calls verarbeiten
                    self._handle_tool_calls(run)
                    # CRITICAL FIX: Nach Tool-Handling direkt weitermachen
                    continue
                    
                elif run.status in ["failed", "cancelled", "expired"]:
                    # ENHANCED ERROR HANDLING: Get detailed error information
                    error_message = f"‚ùå Verarbeitung fehlgeschlagen: {run.status}"
                    
                    # Try to get detailed error information
                    try:
                        if hasattr(run, 'last_error') and run.last_error:
                            error_details = f"Error Code: {run.last_error.code}, Message: {run.last_error.message}"
                            logger.error(f"üö® OPENAI RUN ERROR DETAILS: {error_details}")
                            error_message += f"\nDetails: {error_details}"
                        
                        # Also check run steps for more detailed errors
                        run_steps = self.client.beta.threads.runs.steps.list(
                            thread_id=self.thread.id,
                            run_id=self.current_run.id
                        )
                        
                        for step in run_steps.data:
                            if step.status == "failed" and hasattr(step, 'last_error') and step.last_error:
                                step_error = f"Step Error - Code: {step.last_error.code}, Message: {step.last_error.message}"
                                logger.error(f"üö® OPENAI STEP ERROR: {step_error}")
                                if "Details:" not in error_message:
                                    error_message += f"\nStep Details: {step_error}"
                                    
                    except Exception as error_fetch_error:
                        logger.error(f"‚ùå Could not fetch detailed error info: {error_fetch_error}")
                    
                    self.emit_error(error_message)
                    logger.error(f"üö® FULL RUN FAILURE: Status={run.status}, RunID={run.id}, ThreadID={self.thread.id}")
                    break
                    
                elif run.status in ["queued", "in_progress"]:
                    # Status-Updates f√ºr laufende Verarbeitung (but not for queued - handled above)
                    if run.status != "queued":
                        self.emit_status(f"‚è≥ Verarbeitung l√§uft... (Status: {run.status}, Iteration: {iteration})")
                    
                time.sleep(2)  # L√§ngere Wartezeit f√ºr Tool-intensive Workflows
                iteration += 1
                
            except Exception as e:
                # Bei JSON-Parsing-Fehlern: Kurz warten und weiter versuchen
                if "Extra data" in str(e) or "JSON" in str(e):
                    self.emit_status("‚ö†Ô∏è API-Response-Fehler, versuche erneut...")
                    time.sleep(1)
                    continue
                else:
                    self.emit_error(f"‚ùå Run-Monitoring Fehler: {e}")
                    break
        
        # Timeout-Protection
        if iteration >= max_iterations:
            self.emit_error(f"‚è∞ Timeout: Verarbeitung nach {max_iterations} Iterationen abgebrochen. Bitte versuchen Sie es erneut.")
    
    def _handle_tool_calls(self, run):
        """NEUE DYNAMISCHE VERSION: Verarbeitet Tool-Calls mit DB-Assistant-Routing"""
        tool_outputs = []
        
        for tool_call in run.required_action.submit_tool_outputs.tool_calls:
            function_name = tool_call.function.name
            arguments = json.loads(tool_call.function.arguments)
            
            self.emit_status(f"üîß F√ºhre {function_name} aus...")
            
            # Emit tool call details to frontend
            self.emit_workflow_update({
                'type': 'tool_call_start',
                'function': function_name,
                'arguments': arguments,
                'timestamp': datetime.now().strftime('%H:%M:%S')
            })
            
            try:
                # NEUE DYNAMISCHE TOOL-ROUTING
                if function_name == "create_content":
                    content_type = arguments.get("content_type", "full_content")
                    phase_info = "Outline-Erstellung" if content_type == "outline" else "Volltext-Erstellung"
                    self.emit_status(f"üñäÔ∏è {phase_info} l√§uft...")
                    result = self._call_assistant_by_role("content_creator", arguments)
                    
                elif function_name == "optimize_didactics":
                    self.emit_status(f"üéì Didaktische Optimierung l√§uft...")
                    result = self._call_assistant_by_role("didactic_expert", arguments)
                    
                elif function_name == "critically_review":
                    review_type = arguments.get("review_type", "full_content")
                    review_info = "Outline-Qualit√§tspr√ºfung" if review_type == "outline" else "Finale Qualit√§tspr√ºfung"
                    self.emit_status(f"üîç {review_info} l√§uft...")
                    result = self._call_assistant_by_role("quality_checker", arguments)
                    
                    try:
                        # Quality Assessment f√ºr Scoring
                        quality_result = assess_course_quality(result)
                        
                        # FIXED: Convert 0-100 scale to 0-10 scale
                        overall_score_100 = quality_result.get('overall_score', 0)
                        overall_score_10 = round(overall_score_100 / 10, 1)
                        
                        result = result + f"\n\nüìä Quality Score: {overall_score_10}/10"
                        
                        # Quality Gate Check with correct 0-10 scale
                        if overall_score_10 < 7.0:
                            self.emit_status(f"‚ö†Ô∏è Quality Gate: Score {overall_score_10}/10 - Verbesserung empfohlen")
                        else:
                            self.emit_status(f"‚úÖ Quality Gate: Score {overall_score_10}/10 - Qualit√§tsziel erreicht")
                            
                    except Exception as e:
                        self.emit_status(f"‚ö†Ô∏è Quality Gate Check Fehler: {e}")
                      
                elif function_name == "request_outline_approval":
                    result = self.request_outline_approval(arguments.get("outline", ""), arguments.get("quality_feedback", ""), arguments.get("topic", ""))
                elif function_name == "request_user_feedback":
                    result = self.request_user_feedback(arguments.get("content", ""), arguments.get("question", ""), arguments.get("stage", ""))
                elif function_name == "knowledge_lookup":
                    self.emit_status(f"üìö Wissensbasis-Suche l√§uft...")
                    result = self.knowledge_lookup(arguments.get("query", ""), arguments.get("context", ""))
                else:
                    result = f"‚ùå Unbekannte Tool-Funktion: {function_name}"
                
                # Emit tool call result to frontend
                self.emit_workflow_update({
                    'type': 'tool_call_result',
                    'function': function_name,
                    'result': result if function_name in ['request_outline_approval', 'request_user_feedback', 'knowledge_lookup'] else 'Content generated successfully',
                    'timestamp': datetime.now().strftime('%H:%M:%S')
                })
                
                # Limitiere Output-Gr√∂√üe f√ºr Stabilit√§t
                if len(str(result)) > 3000:
                    result = str(result)[:3000] + "... [Inhalt gek√ºrzt f√ºr Tool-Output]"
                
                tool_outputs.append({
                    "tool_call_id": tool_call.id,
                    "output": str(result)
                })
                
                self.emit_status(f"‚úÖ {function_name} abgeschlossen")
                
            except Exception as tool_error:
                error_msg = f"Tool-Fehler in {function_name}: {str(tool_error)}"
                self.emit_error(error_msg)
                
                # Emit error to workflow
                self.emit_workflow_update({
                    'type': 'tool_call_error',
                    'function': function_name,
                    'error': error_msg,
                    'timestamp': datetime.now().strftime('%H:%M:%S')
                })
                
                tool_outputs.append({
                    "tool_call_id": tool_call.id,
                    "output": error_msg
                })
        
        # Tool-Outputs an OpenAI senden
        try:
            self.emit_status(f"üì§ Sende {len(tool_outputs)} Tool-Outputs an OpenAI...")
            
            self.client.beta.threads.runs.submit_tool_outputs(
                thread_id=self.thread.id,
                run_id=run.id,
                tool_outputs=tool_outputs
            )
            
            # Nach Tool-Outputs weiter √ºberwachen
            self.emit_status("üîÑ Tool-Ausf√ºhrung abgeschlossen, warte auf finale Antwort...")
            
        except Exception as e:
            self.emit_error(f"‚ùå Tool-Output Submission Fehler: {e}")
            # Bei Tool-Output-Fehlern: Versuche Recovery
            self.emit_status("üîÑ Versuche Recovery nach Tool-Output-Fehler...")
            time.sleep(2)
    
    def _call_assistant_by_role(self, role, arguments):
        """NEUE FUNKTION: Ruft Assistant basierend auf Rolle aus Datenbank auf"""
        
        # CRITICAL FIX: Fallback to supervisor if specific role is not available
        if role not in self.assistants:
            logger.warning(f"‚ö†Ô∏è Assistant role '{role}' not found in database, falling back to supervisor")
            if 'supervisor' in self.assistants:
                assistant_data = self.assistants['supervisor']
                logger.info(f"‚úÖ Using supervisor assistant as fallback for {role}")
            else:
                logger.error(f"‚ùå No supervisor assistant available as fallback for {role}")
                return f"Assistant mit Rolle '{role}' nicht in Datenbank konfiguriert und kein Supervisor-Fallback verf√ºgbar."
        else:
            assistant_data = self.assistants[role]
        
        try:
            self.emit_status(f"ü§ñ {assistant_data['name']} arbeitet (Rolle: {role})...")
            
            # Emit agent communication details
            self.emit_workflow_update({
                'type': 'agent_start',
                'agent': assistant_data['name'],
                'role': role,
                'model': assistant_data['model'],
                'timestamp': datetime.now().strftime('%H:%M:%S')
            })
            
            # Je nach Tool-Call die entsprechende Prompt erstellen
            if role == "content_creator":
                prompt = self._create_content_prompt(arguments)
            elif role == "didactic_expert":
                prompt = self._create_didactic_prompt(arguments)
            elif role == "quality_checker":
                prompt = self._create_quality_prompt(arguments)
            else:
                # Generic prompt for any role
                prompt = f"Als {role}: {str(arguments)}"
            
            # Emit the prompt being sent to agent
            self.emit_workflow_update({
                'type': 'agent_prompt',
                'agent': assistant_data['name'],
                'prompt': prompt[:200] + "..." if len(prompt) > 200 else prompt,
                'timestamp': datetime.now().strftime('%H:%M:%S')
            })
            
            # ENHANCED ERROR HANDLING: More detailed OpenAI API call
            logger.info(f"üöÄ Making OpenAI API call for {role} with model {assistant_data['model']}")
            
            # Assistant √ºber OpenAI API aufrufen
            response = self.client.chat.completions.create(
                model=assistant_data['model'],
                messages=[
                    {"role": "system", "content": assistant_data['instructions']},
                    {"role": "user", "content": prompt}
                ],
                temperature=assistant_data.get('temperature', 0.3),
                max_tokens=assistant_data.get('max_tokens', 3000)
            )
            
            result = response.choices[0].message.content
            logger.info(f"‚úÖ OpenAI API call successful for {role}, response length: {len(result)}")
            
            # Emit agent response summary
            self.emit_workflow_update({
                'type': 'agent_response',
                'agent': assistant_data['name'],
                'response': result[:300] + "..." if len(result) > 300 else result,
                'timestamp': datetime.now().strftime('%H:%M:%S')
            })
            
            self.emit_status(f"‚úÖ {assistant_data['name']} abgeschlossen")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå OpenAI API call failed for {role}: {type(e).__name__}: {str(e)}")
            self.emit_error(f"‚ö†Ô∏è {assistant_data['name']} Fehler: {e}")
            return f"{assistant_data['name']} ist momentan nicht verf√ºgbar. Fehler: {str(e)}"
    
    def _create_content_prompt(self, arguments):
        """Erstellt OPTIMIERTEN Prompt f√ºr Content Creator mit Quality-Focus"""
        topic = arguments.get("topic", "")
        instructions = arguments.get("instructions", "")
        
        return f"""üéØ AUFTRAG: Erstelle einen STRUKTUR-OPTIMIERTEN, hochwertigen Kursentwurf f√ºr "{topic}".

üìã QUALITY-REQUIREMENTS (Ziel: >7.5/10 Score):

üèóÔ∏è OBLIGATORISCHE STRUKTUR-ELEMENTE:
‚úÖ Nummerierte Hauptkapitel (1., 2., 3., 4., 5.)
‚úÖ Klare Unterkapitel mit Nummerierung (1.1, 1.2, etc.)
‚úÖ Maximal 3 Hierarchie-Ebenen
‚úÖ Logische Progression: Grundlagen ‚Üí Anwendung ‚Üí Vertiefung

üìö LERNZIELE (OBLIGATORISCH f√ºr Score >5.0):
‚úÖ 3-5 konkrete Lernziele pro Hauptkapitel
‚úÖ Format: "Nach diesem Kapitel k√∂nnen Sie..."
‚úÖ Messbare, spezifische Outcomes
‚úÖ SMART-Kriterien befolgen

üéì DIDAKTISCHE STRUKTUR:
‚úÖ Einf√ºhrung mit Motivation und √úberblick
‚úÖ Jeder Abschnitt: Ziel ‚Üí Inhalt ‚Üí Beispiel ‚Üí Checkpoint
‚úÖ Mindestens 1 praktisches Beispiel pro Hauptkonzept  
‚úÖ Kurze Zusammenfassung am Ende jedes Kapitels
‚úÖ Wissencheck-Fragen nach jedem Hauptkapitel

üìù CONTENT-STANDARDS:
‚úÖ Deutsche Sprache, professionelle Tonalit√§t
‚úÖ Konsistente Terminologie (Glossar-ready)
‚úÖ Verst√§ndlich f√ºr Einsteiger bis Fortgeschrittene
‚úÖ Actionable Content mit klaren Handlungsempfehlungen

üîç QUALIT√ÑTS-CHECKPOINTS:
‚úÖ Jeder Abschnitt <500 W√∂rter f√ºr bessere Lesbarkeit
‚úÖ Bullet Points f√ºr komplexe Listen
‚úÖ Hervorhebungen f√ºr Schl√ºsselbegriffe
‚úÖ Call-to-Action am Ende jedes Abschnitts

ADDITIONAL INSTRUCTIONS:
{instructions}

‚ö° WICHTIG: Nutze knowledge_lookup ZUERST bei hochgeladenen Dateien f√ºr domain-spezifisches Wissen!

üéØ ERFOLGSKRITERIUM: Struktur-Score >8.0, Didaktik-Score >7.0, Gesamt-Score >7.5"""
    
    def _create_didactic_prompt(self, arguments):
        """Erstellt VERST√ÑRKTEN Prompt f√ºr Didactic Expert mit Quality-Enforcement"""
        content = arguments.get("content", "")
        
        return f"""üéì DIDAKTISCHE OPTIMIERUNG: Transformiere den Kurs von 4.0 auf >7.0 Didaktik-Score!

EINGANGSMATERIAL:
{content}

üöÄ OPTIMIERUNGS-ZIELE (Score-Verbesserung):

üìö LERNZIEL-OPTIMIERUNG (Struktur-Boost):
‚úÖ Pr√ºfe: Sind 3-5 Lernziele pro Kapitel vorhanden?
‚úÖ Erweitere fehlende Lernziele im Format: "Nach diesem Kapitel k√∂nnen Sie..."
‚úÖ Konkretisiere vage Ziele zu messbaren Outcomes
‚úÖ Verkn√ºpfe Lernziele mit praktischen Anwendungen

üîç BEISPIEL-INTEGRATION (Didaktik-Boost):
‚úÖ MINIMUM: 2 konkrete Beispiele pro Hauptkonzept
‚úÖ Mix aus: Real-World Cases, Code-Snippets, Step-by-Step Demos
‚úÖ Progressiver Schwierigkeitsgrad: Einfach ‚Üí Komplex
‚úÖ Direkte Verbindung zu Lernzielen herstellen

üìù ZUSAMMENFASSUNGS-STRUKTUR:
‚úÖ Kapitel-Zusammenfassung: 3-5 Kernpunkte als Bullet Points
‚úÖ Lessons Learned: "Das Wichtigste in K√ºrze"  
‚úÖ Next Steps: Klare Handlungsempfehlungen
‚úÖ Checkpoint-Fragen: 2-3 Selbsttest-Fragen

üéØ INTERAKTIVE ELEMENTE:
‚úÖ Reflexions-Prompts: "√úberlegen Sie..." 
‚úÖ Praxis-Aufgaben: "Probieren Sie aus..."
‚úÖ Checklisten f√ºr komplexe Prozesse
‚úÖ "H√§ufige Fehler"-Boxen mit L√∂sungen

üìä VERST√ÑNDLICHKEITS-OPTIMIERUNG:
‚úÖ Komplexe Begriffe sofort erkl√§ren (Glossar-ready)
‚úÖ Lange S√§tze aufteilen (max. 20 W√∂rter/Satz)
‚úÖ Fachbegriffe konsistent verwenden
‚úÖ Logische √úberg√§nge zwischen Abschnitten

üé® STRUKTUR-VERBESSERUNG:
‚úÖ Einheitliche Kapitel-Templates verwenden
‚úÖ Visueller Flow: Intro ‚Üí Content ‚Üí Example ‚Üí Summary ‚Üí Action
‚úÖ Konsistente Formatierung und Hervorhebungen
‚úÖ Klare Hierarchie beibehalten

üéØ ERFOLGSKRITERIUM: Didaktik-Score von 4.0 auf >7.0 steigern durch systematische Verbesserung aller Dimensionen!"""
    
    def _create_quality_prompt(self, arguments):
        """Erstellt GEH√ÑRTETEN Prompt f√ºr Quality Checker mit automatischen Quality Gates"""
        content = arguments.get("content", "")
        feedback = arguments.get("feedback", "")
        
        if feedback:
            # Regeneration mode with specific feedback
            return f"""üîç QUALIT√ÑTS-VERBESSERUNG: Korrigiere den Kurs basierend auf spezifischem Feedback!

URSPR√úNGLICHER KURS:
{content}

VERBESSERUNGS-ANWEISUNGEN:
{feedback}

‚ö° DEINE AUFGABE:
Korrigiere den Kurs systematisch basierend auf dem Feedback und gib den VOLLST√ÑNDIGEN, VERBESSERTEN KURS aus.

üéØ WICHTIG: 
- Gib NUR den korrigierten Kursinhalt aus
- KEIN JSON, keine Bewertung, keine Analyse
- Vollst√§ndiger Kurs mit allen Verbesserungen
- Alle Probleme behoben gem√§√ü Feedback

AUSGABE: Der komplette, verbesserte Kurs in Markdown-Format."""

        else:
            # Standard quality check mode
            return f"""üîç KRITISCHE QUALIT√ÑTSPR√úFUNG: Pr√ºfe und verbessere den Kurs!

ZU PR√úFENDER INHALT:
{content}

üö® DEINE AUFGABEN:

1. QUALIT√ÑTS-ANALYSE:
‚úÖ Struktur pr√ºfen: Lernziele, Hierarchie, Beispiele
‚úÖ Didaktik bewerten: Verst√§ndlichkeit, Progression
‚úÖ Konsistenz validieren: Terminologie, Sprache

2. SOFORTIGE VERBESSERUNG:
‚úÖ Fehlende Lernziele erg√§nzen (3-5 pro Kapitel)
‚úÖ Beispiele hinzuf√ºgen (min. 2 pro Hauptkonzept)
‚úÖ Terminologie vereinheitlichen
‚úÖ S√§tze verk√ºrzen (max. 20 W√∂rter)
‚úÖ Zusammenfassungen erg√§nzen

‚ö° KRITISCH WICHTIG:
Gib den VOLLST√ÑNDIGEN, VERBESSERTEN KURS aus - NICHT das Assessment!

AUSGABE: Der komplette, qualit√§tssichere Kurs in Markdown-Format mit allen Verbesserungen."""
    
    def request_user_feedback(self, content: str, question: str, stage: str) -> str:
        """Bittet User um Feedback im Chat"""
        self.emit_status(f"üë§ Feedback ben√∂tigt f√ºr: {stage}")
        
        # Feedback-Request an Chat senden
        feedback_msg = f"""## ü§î Ihr Feedback ist gefragt!

**Stadium:** {stage}
**Frage:** {question}

{content[:500]}{'...' if len(content) > 500 else ''}

Bitte geben Sie Ihr Feedback oder best√§tigen Sie die Freigabe."""
        
        self.emit_message(feedback_msg, "system")
        return "Warte auf User-Feedback im Chat..."
    
    def request_outline_approval(self, outline: str, quality_feedback: str, topic: str) -> str:
        """Bittet User um Freigabe f√ºr das Inhaltsverzeichnis"""
        self.emit_status(f"ÔøΩÔøΩ Freigabe f√ºr Inhaltsverzeichnis ben√∂tigt f√ºr: '{topic}'")
        
        approval_msg = f"""## ü§î Ihre Freigabe ist gefragt!

**Thema:** {topic}
**Inhaltsverzeichnis:**
{outline}

**Feedback vom Quality Checker:**
{quality_feedback}

Bitte geben Sie Ihre Freigabe oder vorschlagen Sie √Ñnderungen."""
        
        self.emit_message(approval_msg, "system")
        return "Warte auf User-Freigabe im Chat..."
    
    def knowledge_lookup(self, query: str, context: str = "") -> str:
        """Sucht in der projektspezifischen Wissensbasis"""
        self.emit_status(f"üìö Durchsuche Wissensbasis nach: '{query}'...")
        
        try:
            from knowledge_manager import knowledge_lookup
            result = knowledge_lookup(query, self.project_id, context)
            self.emit_status("‚úÖ Wissenssuche abgeschlossen")
            return result
        except Exception as e:
            self.emit_error(f"‚ö†Ô∏è Wissensbasis-Fehler: {e}")
            return f"Die Wissensbasis f√ºr '{query}' ist momentan nicht verf√ºgbar. Ich erstelle den Inhalt basierend auf allgemeinem Wissen."
    
    def _room(self):
        """Bestimmt den korrekten SocketIO-Raum."""
        if self.session_id:
            return f'session_{self.session_id}'
        if self.project_id:
            return f'project_{self.project_id}'
        return None
    
    # SocketIO Hilfsfunktionen (unver√§ndert)
    def emit_message(self, message, sender="assistant", metadata=None):
        """Sendet Nachricht an Chat"""
        room = self._room()
        logger.info(f"üì° EMIT MESSAGE to room {room}: {message[:100]}...")
        self.socketio.emit('new_message', {
            'sender': 'KI-Assistant' if sender == 'assistant' else sender,
            'message': message,
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'type': sender,
            'metadata': metadata or {}
        }, room=room)
    
    def emit_status(self, status):
        """Sendet Status-Update"""
        room = self._room()
        logger.info(f"üì° EMIT STATUS to room {room}: {status}")
        self.socketio.emit('status_update', {
            'status': status,
            'timestamp': datetime.now().strftime('%H:%M:%S')
        }, room=room)
    
    def emit_error(self, error):
        """Sendet Fehler-Nachricht"""
        room = self._room()
        logger.error(f"üì° EMIT ERROR to room {room}: {error}")
        self.socketio.emit('error_message', {
            'error': error,
            'timestamp': datetime.now().strftime('%H:%M:%S')
        }, room=room)
    
    def set_chat_mode(self, mode):
        """Setzt den Chat-Modus (collaborative/autonomous)"""
        self.chat_mode = mode
        self.emit_status(f"üîß Modus ge√§ndert zu: {mode}")

    def _safe_encode(self, text: str) -> str:
        """Encodes large text blocks as BASE64 to avoid JSON issues"""
        return "BASE64:" + base64.b64encode(text.encode("utf-8")).decode("ascii")

    def _safe_decode(self, text: str) -> str:
        if text.startswith("BASE64:"):
            try:
                return base64.b64decode(text[7:].encode("ascii")).decode("utf-8", errors="ignore")
            except Exception:
                return text  # fallback
        return text

    def _emit_course_content_update(self, stage, content):
        """Sendet Kursinhalt-Updates an das Frontend f√ºr das Ergebnis-Fenster"""
        if self.socketio and self.session_id:
            # Decode content if it's base64 encoded
            display_content = self._safe_decode(content) if content.startswith('BASE64:') else content
            
            self.socketio.emit('course_content_update', {
                'stage': stage,
                'content': display_content,
                'timestamp': datetime.now().strftime('%H:%M:%S')
            }, room=f'session_{self.session_id}')

    def emit_workflow_update(self, data):
        """Sendet Workflow-Updates an das Frontend"""
        if self.socketio and self.session_id:
            self.socketio.emit('workflow_update', data, room=f'session_{self.session_id}')

    def _generate_improvement_instructions(self, quality_scores):
        """Generiert spezifische Verbesserungs-Anweisungen basierend auf Quality-Scores"""
        improvements = []
        
        # Extract individual scores
        structure_score = quality_scores.get('component_scores', {}).get('structure', {}).get('score', 0)
        readability_score = quality_scores.get('component_scores', {}).get('readability', {}).get('score', 0) 
        consistency_score = quality_scores.get('component_scores', {}).get('consistency', {}).get('score', 0)
        overall_score = quality_scores.get('overall_score', 0)
        
        # Structure improvements
        if structure_score < 7.0:
            improvements.append(f"""
üèóÔ∏è STRUKTUR-VERBESSERUNG (aktuell: {structure_score:.1f}/10):
- F√ºge 3-5 konkrete Lernziele pro Hauptkapitel hinzu
- Erweitere Beispiele: MINIMUM 2 pro Hauptkonzept
- Erg√§nze Zusammenfassungen am Ende jeder Sektion
- Verbessere Nummerierung und Hierarchie-Struktur
""")
        
        # Readability improvements  
        if readability_score < 7.0:
            improvements.append(f"""
üìñ LESBARKEITS-VERBESSERUNG (aktuell: {readability_score:.1f}/10):
- Teile lange S√§tze auf (max. 20 W√∂rter)
- Erkl√§re Fachbegriffe beim ersten Auftreten
- Vereinfache komplexe Formulierungen
- F√ºge mehr Zwischen√ºberschriften ein
""")
        
        # Consistency improvements
        if consistency_score < 7.0:
            improvements.append(f"""
üéØ KONSISTENZ-VERBESSERUNG (aktuell: {consistency_score:.1f}/10):
- Verwende Fachbegriffe durchgehend einheitlich
- Standardisiere Format und Tonalit√§t  
- Korrigiere widerspr√ºchliche Aussagen
- Vereinheitliche Beispiel-Struktur
""")
        
        # Overall quality enforcement
        if overall_score < 7.0:
            improvements.append(f"""
‚ö†Ô∏è QUALIT√ÑTS-GATE: Gesamt-Score {overall_score:.1f}/10 nicht ausreichend!
ZIEL: Mindestens 7.5/10 f√ºr Production-Release erforderlich.
F√ºhre ALLE oben genannten Verbesserungen systematisch durch.
""")
        
        return "\n".join(improvements) if improvements else "‚úÖ Qualit√§t ausreichend - keine Verbesserungen erforderlich."

    def _is_course_creation_complete(self, response: str) -> bool:
        """Pr√ºft, ob die KI-Antwort ein Indikator f√ºr das Abschluss des Kurserstellungsprozesses ist."""
        # More comprehensive completion indicators
        completion_indicators = [
            "Kurs wurde erfolgreich erstellt",
            "Der Kurs ist jetzt bereit",
            "Kurserstellung abgeschlossen",
            "Ihr Kurs ist fertig",
            "Der komplette Kurs"
        ]
        
        return any(indicator in response for indicator in completion_indicators)

    def _save_course_to_database(self, content: str):
        """Speichert den erstellten Kursinhalt in der Datenbank."""
        try:
            from models import db, Course, CourseSection
            from flask import current_app
            import json
            import re
            
            # CRITICAL FIX: Ensure we're in Flask app context
            with current_app.app_context():
                
                # Extract course metadata from content
                title = self._extract_course_title(content)
                description = self._extract_course_description(content)
                topic = self._extract_course_topic(content)
                
                logger.info(f"üéì Saving course: '{title}' for user {self.session_id}")
                
                # Create new course record
                new_course = Course(
                    user_id=int(self.session_id) if self.session_id else 1,  # Fallback to user 1
                    project_id=int(self.project_id) if self.project_id and self.project_id != 'default' else None,
                    title=title,
                    description=description,
                    course_topic=topic,
                    full_content=content,
                    content_length=len(content),
                    status='draft'  # Set as draft initially
                )
                
                db.session.add(new_course)
                db.session.flush()  # Get the course ID
                
                # Extract and save course sections if possible
                sections = self._extract_course_sections(content)
                for i, section in enumerate(sections):
                    course_section = CourseSection(
                        course_id=new_course.id,
                        section_title=section.get('title', f'Kapitel {i+1}'),
                        section_content=section.get('content', ''),
                        section_order=i + 1,
                        section_type='chapter'
                    )
                    db.session.add(course_section)
                
                db.session.commit()
                
                logger.info(f"‚úÖ Course saved with ID {new_course.id}: '{title}' ({len(sections)} sections)")
                
                # Store course ID for follow-up messages
                self.last_saved_course_id = new_course.id
                self.last_saved_course_title = title
                
                # Send helpful completion message to user
                completion_message = f"""‚úÖ **Kurs erfolgreich gespeichert!**

**üìö {title}**
- **Kapitel:** {len(sections)}
- **Umfang:** {len(content):,} Zeichen
- **Status:** Entwurf

**üîó Wo finde ich meinen Kurs?**
‚ûú [Zu "Meine Kurse"](/courses) - Alle gespeicherten Kurse
‚ûú [Diesen Kurs anzeigen](/courses/{new_course.id}) - Direkt zum Kurs

**üì• Aktionen:**
- Download als Textdatei
- In Zwischenablage kopieren
- Kurs bearbeiten oder ver√∂ffentlichen

Ihr Kurs wurde sicher in der Datenbank gespeichert und ist jederzeit abrufbar!"""

                # Emit completion message
                self.emit_message(completion_message, "assistant")
                
                # Emit course completion event to frontend
                self.emit_workflow_update({
                    'type': 'course_saved',
                    'course_id': new_course.id,
                    'title': title,
                    'status': 'saved',
                    'sections_count': len(sections),
                    'content_length': len(content),
                    'course_url': f'/courses/{new_course.id}'
                })
                
        except Exception as e:
            logger.error(f"‚ùå Error saving course to database: {type(e).__name__}: {str(e)}")
            self.emit_error(f"‚ùå Fehler beim Speichern des Kurses: {str(e)}")
            
    def _extract_course_title(self, content: str) -> str:
        """Extract course title from content"""
        # Look for markdown h1 or common title patterns
        title_patterns = [
            r'^#\s+(.+?)$',  # Markdown H1
            r'^\*\*(.+?)\*\*$',  # Bold title
            r'^(.+?)\s*(?:Kurs|Course)',  # Text before "Kurs" or "Course"
        ]
        
        lines = content.split('\n')
        for line in lines[:10]:  # Check first 10 lines
            line = line.strip()
            if not line:
                continue
            for pattern in title_patterns:
                match = re.search(pattern, line, re.MULTILINE)
                if match:
                    return match.group(1).strip()
        
        # Fallback: use first non-empty line or generate title
        for line in lines[:5]:
            if line.strip():
                return line.strip()[:100]  # Max 100 chars
                
        return f"KI-Kurs erstellt am {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    def _extract_course_description(self, content: str) -> str:
        """Extract course description from content"""
        lines = content.split('\n')
        description_lines = []
        
        # Look for description after title
        found_title = False
        for line in lines:
            line = line.strip()
            if not line:
                continue
            if not found_title and (line.startswith('#') or line.startswith('**')):
                found_title = True
                continue
            if found_title and len(description_lines) < 3:
                if not line.startswith('#') and not line.startswith('**'):
                    description_lines.append(line)
                else:
                    break
        
        return ' '.join(description_lines)[:500] if description_lines else "KI-generierter Kurs"
    
    def _extract_course_topic(self, content: str) -> str:
        """Extract course topic from content"""
        # This could be enhanced to extract from the original user input
        # For now, try to extract from the content
        if hasattr(self, '_original_topic') and self._original_topic:
            return self._original_topic
        
        # Try to extract from title
        title = self._extract_course_title(content)
        if 'AI' in title or 'KI' in title or 'Agent' in title:
            return 'AI & Machine Learning'
        elif 'Python' in title or 'Programm' in title:
            return 'Programming'
        elif 'Business' in title or 'Marketing' in title:
            return 'Business'
        else:
            return 'Allgemein'
    
    def _extract_course_sections(self, content: str) -> list:
        """Extract course sections from content"""
        sections = []
        lines = content.split('\n')
        current_section = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            
            # Detect section headers (markdown H2, H3, or numbered)
            if (line.startswith('##') or 
                re.match(r'^\d+\.', line) or 
                re.match(r'^[A-Z][^.]*:$', line)):
                
                # Save previous section
                if current_section:
                    sections.append({
                        'title': current_section,
                        'content': '\n'.join(current_content).strip()
                    })
                
                # Start new section
                current_section = line.replace('#', '').strip()
                current_content = []
            else:
                if current_section and line:
                    current_content.append(line)
        
        # Save last section
        if current_section:
            sections.append({
                'title': current_section,
                'content': '\n'.join(current_content).strip()
            })
        
        return sections
    
    def _detect_intent(self, message: str) -> str:
        """
        Simple intent detection to categorize user messages
        Returns: 'greeting', 'small_talk', 'course_request', 'other'
        """
        message_lower = message.lower().strip()
        message_len = len(message)
        
        # Greeting patterns
        greeting_patterns = [
            'hallo', 'hi', 'hey', 'guten tag', 'guten morgen', 'guten abend',
            'servus', 'moin', 'hall√∂chen', 'gr√º√ü gott', 'gr√º√ü dich'
        ]
        
        # Small talk patterns
        small_talk_patterns = [
            'wie geht', 'was machst du', 'was kannst du', 'wer bist du',
            'danke', 'dankesch√∂n', 'vielen dank', 'super', 'toll', 'prima',
            'ok', 'okay', 'alles klar', 'verstehe', 'gut'
        ]
        
        # Course request patterns  
        course_patterns = [
            'kurs', 'erstell', 'training', 'schulung', 'lerninhalt',
            'lektion', 'tutorial', 'workshop', 'seminar', 'modul'
        ]
        
        # Check for greetings (prioritize short messages)
        if message_len <= 20:
            for pattern in greeting_patterns:
                if pattern in message_lower:
                    return 'greeting'
        
        # Check for small talk
        for pattern in small_talk_patterns:
            if pattern in message_lower:
                return 'small_talk'
        
        # Check for course requests
        for pattern in course_patterns:
            if pattern in message_lower:
                return 'course_request'
        
        # Default classification based on length and content
        if message_len <= 30 and not any(p in message_lower for p in course_patterns):
            return 'small_talk'
        
        return 'other'
    
    def _handle_simple_response(self, message: str, intent: str):
        """
        Handle simple responses for greetings and small talk without triggering workflow
        """
        self._update_activity()
        
        if intent == 'greeting':
            responses = [
                "Hallo! Sch√∂n, Sie zu sehen. Wie kann ich Ihnen heute helfen?",
                "Hi! Ich bin Ihr KI-Assistent f√ºr die Kurserstellung. Was kann ich f√ºr Sie tun?",
                "Guten Tag! M√∂chten Sie einen neuen Kurs erstellen oder haben Sie Fragen?",
                "Hallo! Ich freue mich, Ihnen bei der Kurserstellung helfen zu k√∂nnen."
            ]
        elif intent == 'small_talk':
            if any(word in message.lower() for word in ['danke', 'dankesch√∂n', 'vielen dank']):
                responses = [
                    "Gerne! Falls Sie weitere Fragen haben, bin ich da.",
                    "Sehr gerne! Kann ich Ihnen noch bei etwas anderem helfen?",
                    "Freut mich, dass ich helfen konnte!"
                ]
            elif any(word in message.lower() for word in ['wie geht', 'was machst du', 'was kannst du']):
                responses = [
                    "Ich bin Ihr KI-Assistent f√ºr die automatische Kurserstellung. Ich kann professionelle Lerninhalte zu jedem Thema erstellen.",
                    "Mir geht es gut, danke! Ich helfe dabei, hochwertige Online-Kurse zu entwickeln. Haben Sie ein bestimmtes Thema im Kopf?",
                    "Ich spezialisiere mich auf die Erstellung von strukturierten Lerninhalten mit didaktischer Optimierung."
                ]
            else:
                responses = [
                    "Das freut mich! M√∂chten Sie einen Kurs zu einem bestimmten Thema erstellen?",
                    "Sch√∂n! Womit kann ich Ihnen konkret helfen?",
                    "Wenn Sie Fragen haben oder einen Kurs erstellen m√∂chten, sagen Sie einfach Bescheid!"
                ]
        else:
            responses = ["Wie kann ich Ihnen helfen?"]
        
        # Select first response (can be randomized later)
        response = responses[0]
        
        # Send response directly without workflow
        self.emit_message(response, "assistant")
        logger.info(f"üì§ Simple response sent for {intent}: {response[:50]}...")

# Legacy-Kompatibilit√§t f√ºr bestehenden Code
ChatOrchestrator = DynamicChatOrchestrator

# Global orchestrator instance f√ºr Web-App Integration
active_orchestrators = {} 