#!/usr/bin/env python3
"""
Test Use Cases f√ºr Multi-Agenten-Kursgenerator
MVP-TODO-003: Konkrete Szenarien f√ºr System-Validierung
"""

import sys
import json
from datetime import datetime
from orchestrator import ContentOrchestrator
from quality_assessment import QualityAssessment
from chat_orchestrator import DynamicChatOrchestrator

class TestUseCases:
    def __init__(self):
        self.orchestrator = ContentOrchestrator()
        self.quality_assessment = QualityAssessment()
        self.results = []
    
    def test_case_1_marketing_beginner(self):
        """
        Test Case 1: Marketing-Kurs f√ºr Anf√§nger
        Zielgruppe: Unternehmer ohne Marketing-Vorkenntnisse
        Lernziel: Grundlagen digitales Marketing in 4 Wochen
        """
        print("üéØ TEST CASE 1: Marketing-Kurs f√ºr Anf√§nger")
        print("="*60)
        
        course_request = {
            "title": "Digitales Marketing f√ºr Einsteiger",
            "target_audience": "Unternehmer und Selbstst√§ndige ohne Marketing-Vorkenntnisse",
            "learning_objectives": [
                "Verstehen der wichtigsten Digital Marketing Kan√§le",
                "Erstellen einer einfachen Marketing-Strategie", 
                "Grundlagen Social Media Marketing",
                "Messbare Ziele definieren und ROI berechnen"
            ],
            "duration": "4 Wochen",
            "format": "Online-Kurs mit praktischen √úbungen",
            "complexity_level": "Beginner"
        }
        
        print(f"üìã Kurs-Anfrage: {course_request['title']}")
        print(f"üéì Zielgruppe: {course_request['target_audience']}")
        print(f"‚è±Ô∏è Dauer: {course_request['duration']}")
        
        # Test durchf√ºhren
        result = self._run_test_workflow(course_request, "marketing_beginner")
        return result
    
    def test_case_2_data_analysis_advanced(self):
        """
        Test Case 2: Datenanalyse-Kurs f√ºr Fortgeschrittene
        Zielgruppe: Data Analysts mit Python-Grundkenntnissen
        Lernziel: Advanced Analytics & Machine Learning
        """
        print("\nüéØ TEST CASE 2: Datenanalyse-Kurs f√ºr Fortgeschrittene")
        print("="*60)
        
        course_request = {
            "title": "Advanced Data Analytics mit Python",
            "target_audience": "Data Analysts mit 1-2 Jahren Python-Erfahrung",
            "learning_objectives": [
                "Statistische Modellierung und Hypothesentests",
                "Machine Learning Algorithmen implementieren",
                "Datenvisualisierung mit Plotly und Seaborn",
                "A/B Testing und experimentelles Design",
                "Big Data Processing mit Pandas und Dask"
            ],
            "duration": "8 Wochen",
            "format": "Hands-on Workshop mit realen Datasets",
            "complexity_level": "Advanced"
        }
        
        print(f"üìã Kurs-Anfrage: {course_request['title']}")
        print(f"üéì Zielgruppe: {course_request['target_audience']}")
        print(f"‚è±Ô∏è Dauer: {course_request['duration']}")
        
        # Test durchf√ºhren
        result = self._run_test_workflow(course_request, "data_analysis_advanced")
        return result
    
    def test_case_3_intent_detection(self):
        """
        Test Case 3: Intent Detection f√ºr Begr√º√üungen
        Testet, dass einfache Begr√º√üungen keinen Workflow ausl√∂sen
        """
        print("\nüéØ TEST CASE 3: Intent Detection - Begr√º√üungen")
        print("="*60)
        
        # Mock SocketIO f√ºr Tests
        class MockSocketIO:
            def emit(self, event, data, room=None):
                pass
        
        # Test-Nachrichten
        test_messages = [
            "Hallo",
            "Hi",
            "Guten Tag",
            "Was kannst du?",
            "Danke",
            "Wie geht es dir?",
            # Negative Tests (sollten Workflow ausl√∂sen)
            "Erstelle einen Kurs √ºber Python",
            "Ich brauche ein Training zu Vertrieb"
        ]
        
        expected_intents = [
            "greeting",     # Hallo
            "greeting",     # Hi  
            "greeting",     # Guten Tag
            "small_talk",   # Was kannst du?
            "small_talk",   # Danke
            "small_talk",   # Wie geht es dir?
            "course_request", # Erstelle einen Kurs √ºber Python
            "course_request"  # Ich brauche ein Training zu Vertrieb
        ]
        
        print("üìã Teste Intent-Erkennung mit verschiedenen Nachrichten...")
        
        orchestrator = DynamicChatOrchestrator(
            socketio=MockSocketIO(),
            project_id="test",
            session_id="test_intent"
        )
        
        results = []
        for i, message in enumerate(test_messages):
            detected_intent = orchestrator._detect_intent(message)
            expected_intent = expected_intents[i]
            
            is_correct = detected_intent == expected_intent
            results.append({
                "message": message,
                "expected": expected_intent,
                "detected": detected_intent,
                "correct": is_correct
            })
            
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"{status} '{message}' ‚Üí {detected_intent} (erwartet: {expected_intent})")
        
        # Zusammenfassung
        correct_count = sum(1 for r in results if r["correct"])
        total_count = len(results)
        accuracy = (correct_count / total_count) * 100
        
        print(f"\nüìä ERGEBNISSE Intent Detection:")
        print(f"   Korrekt erkannt: {correct_count}/{total_count} ({accuracy:.1f}%)")
        
        # Test-Ergebnis f√ºr Summary
        test_result = {
            "test_id": "intent_detection",
            "test_type": "intent_classification",
            "accuracy": accuracy,
            "correct_predictions": correct_count,
            "total_predictions": total_count,
            "details": results,
            "status": "completed" if accuracy >= 80 else "failed",
            "timestamp": datetime.now().isoformat()
        }
        
        self.results.append(test_result)
        
        if accuracy >= 80:
            print("‚úÖ INTENT DETECTION TEST PASSED (‚â•80% Accuracy)")
        else:
            print("‚ùå INTENT DETECTION TEST FAILED (<80% Accuracy)")
        
        return test_result
    
    def _run_test_workflow(self, course_request, test_id):
        """
        F√ºhrt den kompletten Workflow f√ºr einen Test-Case durch
        """
        print(f"\nüöÄ Starte Workflow f√ºr {test_id}...")
        
        start_time = datetime.now()
        
        try:
            # 1. Content Creation
            print("üìù Step 1: Content Creation...")
            # Erstelle instructions String aus course_request
            instructions = f"""
Zielgruppe: {course_request['target_audience']}
Dauer: {course_request['duration']}
Format: {course_request['format']}
Komplexit√§t: {course_request['complexity_level']}

Lernziele:
""" + "\n".join(f"- {obj}" for obj in course_request['learning_objectives'])
            
            content_result = self.orchestrator.create_content(
                topic=course_request['title'],
                instructions=instructions
            )
            
            # 2. Didactic Optimization
            print("üéì Step 2: Didactic Optimization...")
            didactic_result = self.orchestrator.optimize_didactics(
                content=content_result
            )
            
            # 3. Quality Assessment (Critical Thinker 2.0)
            print("üîç Step 3: Quality Assessment...")
            quality_scores = self.quality_assessment.assess_content(didactic_result)
            
            # 4. Critical Review
            print("üí≠ Step 4: Critical Review...")
            review_result = self.orchestrator.critically_review(
                content=didactic_result
            )
            
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            
            # Ergebnis zusammenfassen
            test_result = {
                "test_id": test_id,
                "course_request": course_request,
                "processing_time_seconds": processing_time,
                "quality_scores": quality_scores,
                "content_length": len(didactic_result),
                "critical_review": review_result,
                "timestamp": datetime.now().isoformat(),
                "status": "completed"
            }
            
            self.results.append(test_result)
            
            # Ergebnis anzeigen
            self._display_test_results(test_result)
            
            return test_result
            
        except Exception as e:
            error_result = {
                "test_id": test_id,
                "error": str(e),
                "status": "failed",
                "timestamp": datetime.now().isoformat()
            }
            self.results.append(error_result)
            print(f"‚ùå Test {test_id} fehlgeschlagen: {e}")
            return error_result
    
    def _display_test_results(self, result):
        """
        Zeigt die Test-Ergebnisse in √ºbersichtlicher Form an
        """
        print(f"\nüìä ERGEBNISSE: {result['test_id']}")
        print("-" * 50)
        print(f"‚è±Ô∏è Verarbeitungszeit: {result['processing_time_seconds']:.2f}s")
        print(f"üìÑ Content-L√§nge: {result['content_length']} Zeichen")
        
        if 'quality_scores' in result:
            scores = result['quality_scores']
            print(f"\nüéØ QUALITY SCORES:")
            
            # Handle nested structure from QualityAssessment.assess_content()
            if 'component_scores' in scores:
                components = scores['component_scores']
                print(f"   üìñ Lesbarkeit: {components.get('readability', {}).get('score', 'N/A')}")
                print(f"   üèóÔ∏è Struktur: {components.get('structure', {}).get('score', 'N/A')}")
                print(f"   üîó Konsistenz: {components.get('consistency', {}).get('score', 'N/A')}")
                print(f"   ‚≠ê Gesamt: {scores.get('overall_score', 'N/A')}")
            else:
                # Fallback for direct score structure
                print(f"   üìñ Lesbarkeit: {scores.get('readability_score', 'N/A')}")
                print(f"   üèóÔ∏è Struktur: {scores.get('structure_score', 'N/A')}")
                print(f"   üîó Konsistenz: {scores.get('consistency_score', 'N/A')}")
                print(f"   ‚≠ê Gesamt: {scores.get('overall_score', 'N/A')}")
        
        # Performance Check
        if result['processing_time_seconds'] > 90:
            print("‚ö†Ô∏è PERFORMANCE WARNING: >90s (Target: <90s)")
        else:
            print("‚úÖ PERFORMANCE OK: <90s")
    
    def run_all_tests(self):
        """
        F√ºhrt alle Test-Cases aus und erstellt einen Summary-Report
        """
        print("üß™ STARTING TEST SUITE - Multi-Agenten-Kursgenerator")
        print("="*70)
        
        # Test Case 1
        result1 = self.test_case_1_marketing_beginner()
        
        # Test Case 2  
        result2 = self.test_case_2_data_analysis_advanced()
        
        # Test Case 3: Intent Detection
        result3 = self.test_case_3_intent_detection()
        
        # Summary Report
        self._generate_summary_report()
        
        return self.results
    
    def _generate_summary_report(self):
        """
        Erstellt einen Summary-Report aller Tests
        """
        print("\nüìã SUMMARY REPORT")
        print("="*50)
        
        successful_tests = [r for r in self.results if r['status'] == 'completed']
        failed_tests = [r for r in self.results if r['status'] == 'failed']
        
        print(f"‚úÖ Erfolgreiche Tests: {len(successful_tests)}/{len(self.results)}")
        print(f"‚ùå Fehlgeschlagene Tests: {len(failed_tests)}/{len(self.results)}")
        
        if successful_tests:
            avg_time = sum(r['processing_time_seconds'] for r in successful_tests) / len(successful_tests)
            print(f"‚è±Ô∏è Durchschnittliche Verarbeitungszeit: {avg_time:.2f}s")
            
            # Performance Check
            if avg_time <= 90:
                print("üéØ PERFORMANCE TARGET ERREICHT (<90s)")
            else:
                print("‚ö†Ô∏è PERFORMANCE TARGET VERFEHLT (>90s)")
        
        # Ergebnisse in JSON speichern
        self._save_results_to_file()
    
    def _save_results_to_file(self):
        """
        Speichert die Test-Ergebnisse in JSON-Datei
        """
        filename = f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Ergebnisse gespeichert in: {filename}")

def main():
    """
    Hauptfunktion f√ºr Test-Ausf√ºhrung
    """
    if len(sys.argv) > 1:
        test_case = sys.argv[1].lower()
        tester = TestUseCases()
        
        if test_case == "marketing":
            tester.test_case_1_marketing_beginner()
        elif test_case == "data":
            tester.test_case_2_data_analysis_advanced()
        elif test_case == "intent":
            tester.test_case_3_intent_detection()
        elif test_case == "all":
            tester.run_all_tests()
        else:
            print("Usage: python test_use_cases.py [marketing|data|intent|all]")
    else:
        # Default: Alle Tests ausf√ºhren
        tester = TestUseCases()
        tester.run_all_tests()

if __name__ == "__main__":
    main() 